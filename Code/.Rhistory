WB <- WB[,-2]
panel <- merge(panel, WB, by.x = c("Dest.Code", "Year"), by.y = c("ccode", "Year"), all.x =TRUE)
colnames(panel)[30] <- "Dest.pop"
colnames(panel)[31] <- "Dest.TO"
colnames(panel)[32] <- "Dest.GDP.g"
panel <- merge(panel, WB, by.x = c("Origin.Code", "Year"), by.y = c("ccode", "Year"), all.x =TRUE)
colnames(panel)[33] <- "Origin.pop"
colnames(panel)[34] <- "Origin.TO"
colnames(panel)[35] <- "Origin.GDP.g"
rm(WB)
# Political Violence
violence <- read.csv("pv_total.csv", stringsAsFactors=FALSE)    #Political Violence
violence <- subset(violence, violence$year>2000 & violence$year<2013)
violence <- violence[,-3]
violence <- violence[,-1]
violence$ccode <- ifelse(violence$ccode==818, 816, violence$ccode)
panel <- merge(panel, violence, by.x = c("Dest.cown", "Year"), by.y = c("ccode", "year"), all.x =TRUE)
colnames(panel)[36] <- "Dest.pv"
panel <- merge(panel, violence, by.x = c("Origin.cown", "Year"), by.y = c("ccode", "year"), all.x =TRUE)
colnames(panel)[37] <- "Origin.pv"
rm(violence)
# PTA network
PTA_s <- read.csv("PTA_sign.csv", stringsAsFactors=FALSE)       #PTA signed
PTA_w <- read.csv("PTA_withdrawal.csv", stringsAsFactors=FALSE) #PTA withdrew
PTA_d <- read.csv("PTA_depth.csv", stringsAsFactors=FALSE)      #PTA withdrew
# remove unnessecary variables from depth
PTA_d <- PTA_d[,1:6]
PTA_d <- PTA_d[,-2:-4]
# clean and change signing data
PTA_s <- PTA_s[,2:8]
PTA_s$ISO1 <- countrycode(PTA_s$ISO1, "iso3n", "cown")
PTA_s$ISO2 <- countrycode(PTA_s$ISO2, "iso3n", "cown")
PTA_s <- PTA_s[,-3:-4]
colnames(PTA_s)[5] <- "pta_s.year"
colnames(PTA_s)[4] <- "pta_name"
# clean and change withdraw
PTA_w <- PTA_w[,2:8]
PTA_w$ISO1 <- countrycode(PTA_w$ISO1, "iso3n", "cown")
PTA_w$ISO2 <- countrycode(PTA_w$ISO2, "iso3n", "cown")
PTA_w <- PTA_w[,-3:-4]
PTA_w <- PTA_w[,-4]
colnames(PTA_w)[4] <- "pta_w.year"
#merge ptas together
pta <- merge(PTA_s, PTA_w, by = c("ISO1","ISO2","NumberSimple"),  all.x =TRUE)
pta <- merge(pta, PTA_d, by = c("NumberSimple"),  all.x =TRUE)
rm(PTA_s, PTA_w, PTA_d)
#clean pta dataset
pta <- subset(pta, pta$pta_w.year>2000 | is.na(pta$pta_w.year))
pta <- subset(pta, pta$pta_s.year<2013)
pta <- subset(pta, is.na(pta$pta_w.year))# all those with withdraw, happened same year, didn't include
pta <- pta[,-1]
pta <- pta[,-5]
pta <- pta[,-3]
pta$pta_s.year <- ifelse(pta$pta_s.year<2001, 2001, pta$pta_s.year)
pta <- summaryBy(depth_index + depth_rasch_new ~ ISO1+ISO2+pta_s.year,
data=pta, FUN=max)
#merge pta data to panel
library(dplyr)
library(zoo)
panel <- merge(panel, pta, by.x = c("Origin.cown", "Dest.cown", "Year"),
by.y = c("ISO1","ISO2", "pta_s.year"), all.x =TRUE)
panel <- merge(panel, pta, by.x = c("Origin.cown", "Dest.cown", "Year"),
by.y = c("ISO2", "ISO1", "pta_s.year"), all.x =TRUE)
panel$depth_index.max.x <- ifelse(is.na(panel$depth_index.max.x),
panel$depth_index.max.y,panel$depth_index.max.x)
panel$depth_rasch_new.max.x <- ifelse(is.na(panel$depth_rasch_new.max.x),
panel$depth_rasch_new.max.y,panel$depth_rasch_new.max.x)
panel <- panel[order(panel$dyadid, panel$Year),]
na.locf2 <- function(x) na.locf(x, na.rm = FALSE)
panel <- transform(panel, depth_index.max.x = ave(depth_index.max.x, dyadid, FUN = na.locf2))
panel <- transform(panel, depth_rasch_new.max.x = ave(depth_rasch_new.max.x, dyadid, FUN = na.locf2))
panel <- panel[,1:39]
colnames(panel)[38] <- "depth_index"
colnames(panel)[39] <- "depth_latent"
panel$depth_index <- ifelse(is.na(panel$depth_index),0,panel$depth_index)
panel$depth_latent <- ifelse(!is.na(panel$depth_latent),
panel$depth_latent - min(na.omit(panel$depth_latent)),
panel$depth_latent)
panel$depth_latent <- ifelse(is.na(panel$depth_latent),0,panel$depth_latent)
rm(pta)
# Supply Chains: imports, COU is desination
trade_end <- read.csv("oecd_enduse.csv", stringsAsFactors=FALSE)
trade_int <- read.csv("oecd_intmed.csv", stringsAsFactors=FALSE)
trade <- rbind(trade_end, trade_int)
rm(trade_end, trade_int)
# clean off variables
trade <- trade[,-2:-4]
trade <- trade[,-3]
trade <- trade[,-4:-9]
trade <- trade[,-5:-10]
trade <- trade[,1:5]
#split into four datasets
mix <- subset(trade, trade$CAT=="XMIXED")
mix <- mix[,-3]
colnames(mix)[4] <- "trade_mix"
cap <- subset(trade, trade$CAT=="CAP")
cap <- cap[,-3]
colnames(cap)[4] <- "trade_cap"
int <- subset(trade, trade$CAT=="INT")
int <- int[,-3]
colnames(int)[4] <- "trade_int"
hco <- subset(trade, trade$CAT=="CONS")
hco <- hco[,-3]
colnames(hco)[4] <- "trade_hco"
rm(trade)
#merge to panel
panel <- merge(panel, hco, by.x = c("Dest.Code", "Origin.Code", "Year"),
by.y = c("COU", "PAR", "Time"), all.x =TRUE)
panel[,40] <- ifelse(is.na(panel[,40]), 0, panel[,40])
panel <- merge(panel, int, by.x = c("Dest.Code", "Origin.Code", "Year"),
by.y = c("COU", "PAR", "Time"), all.x =TRUE)
panel[,41] <- ifelse(is.na(panel[,41]), 0, panel[,41])
panel <- merge(panel, cap, by.x = c("Dest.Code", "Origin.Code", "Year"),
by.y = c("COU", "PAR", "Time"), all.x =TRUE)
panel[,42] <- ifelse(is.na(panel[,42]), 0, panel[,42])
panel <- merge(panel, mix, by.x = c("Dest.Code", "Origin.Code", "Year"),
by.y = c("COU", "PAR", "Time"), all.x =TRUE)
panel[,43] <- ifelse(is.na(panel[,43]), 0, panel[,43])
rm(mix, cap, int, hco)
# Transparency
transparency <- read.csv("cpi.csv", stringsAsFactors=FALSE)     #Transparency Score
#wide to long
years <- colnames(transparency)[3:20]
transparency <- reshape(transparency, varying = years, v.names = "trans_score",
timevar = "year", times = years,
direction="long")
transparency <- transparency[,2:4]
transparency$year <- gsub("X", "",transparency$year)
transparency$year <- as.numeric(transparency$year)
transparency <- subset(transparency, transparency$year>2000 & transparency$year<2013)
#merge
panel <- merge(panel, transparency, by.x = c("Destination", "Year"),
by.y = c("Jurisdiction","year"), all.x =TRUE)
colnames(panel)[44] <- "t.score_Dest"
panel <- merge(panel, transparency, by.x = c("Origin", "Year"),
by.y = c("Jurisdiction","year"), all.x =TRUE)
colnames(panel)[45] <- "t.score_Origin"
rm(transparency, years)
View(panel)
write.csv(panel, file = "panel_stock.csv")
#=============================================================#
# John Schoeneman
# Work Done For: FDI Network Analysis RA-IGERT
# Date: Fall 2016
# Work Done: Network Measures and MRQAP
# Machine: MacPro OSX Yosemite
#=============================================================#
# clear workspace
rm(list=ls())
set.seed(19)
# libraries
library(GERGM)
library(network)
library(igraph)
library(doBy)
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#load in data
fdi <- read.csv("panel_stock.csv", stringsAsFactors=FALSE)        #FDI
fdi$Value <- ifelse(is.na(fdi$Value), 0, fdi$Value)
fdi$defense.max.x <- ifelse(is.na(fdi$defense.max.x), 0, fdi$defense.max.x)
fdi$nonaggression.max.x <- ifelse(is.na(fdi$nonaggression.max.x), 0, fdi$nonaggression.max.x)
fdi$neutrality.max.x <- ifelse(is.na(fdi$neutrality.max.x), 0, fdi$neutrality.max.x)
fdi$entente.max.x <- ifelse(is.na(fdi$entente.max.x), 0, fdi$entente.max.x)
fdi <- fdi[c("Destination","Origin","Year",  "Value", "contig","comlang_off", "comlang_ethno","colony",
"comcol", "curcol","dist","Dest.GDP","Origin.GDP","defense.max.x","nonaggression.max.x",
"neutrality.max.x","entente.max.x","Dest.polity","Origin.polity","Dest.TO", "Dest.GDP.g",
"Origin.pop", "Origin.TO", "Origin.GDP.g", "Dest.pv", "Origin.pv", "depth_index", "depth_latent",
"trade_hco", "trade_int", "trade_cap", "trade_mix")]
fdi01 <- subset(fdi, fdi$Year ==2001)
for(i in 3:32){
fdi01[,i] <- as.numeric(fdi01[,i])
}
fdi01 <- na.omit(fdi01)
names <- data.frame(unique(fdi01$Destination))
colnames(names)[1] <- "Destination"
names$year = 2001
for(i in 2002:2012){
fdi_t <- subset(fdi, fdi$Year ==i)
for(i in 3:32){
fdi_t[,i] <- as.numeric(fdi_t[,i])
}
fdi_t <- na.omit(fdi_t)
names_t <- data.frame(unique(fdi_t$Destination))
colnames(names_t)[1] <- "Destination"
names_t$year = i
names <- merge(names, names_t, by = "Destination")
}
fdi01 <- subset(fdi, fdi$Year ==2001)
for(i in 3:32){
fdi01[,i] <- as.numeric(fdi01[,i])
}
fdi01 <- na.omit(fdi01)
names2 <- data.frame(unique(fdi01$Origin))
colnames(names2)[1] <- "Destination"
names2$year = 2001
for(i in 2002:2012){
fdi_t <- subset(fdi, fdi$Year ==i)
for(i in 3:32){
fdi_t[,i] <- as.numeric(fdi_t[,i])
}
fdi_t <- na.omit(fdi_t)
names_t <- data.frame(unique(fdi_t$Origin))
colnames(names_t)[1] <- "Destination"
names_t$year = i
names2 <- merge(names2, names_t, by = "Destination")
}
names3 <- merge(names, names2, by = "Destination")
names <- data.frame(unique(names3$Destination))
rm(fdi_t, fdi01, names_t, names2, names3, i)
colnames(names)[1] <- "Country"
names$new = 1
fdi_n  <- merge(fdi, names, by.x = "Destination", by.y = "Country")
fdi_n <- fdi_n[,-33]
fdi_n  <- merge(fdi, names, by.x = "Origin", by.y = "Country")
fdi_n <- fdi_n[,-33]
fdi_n <- unique(fdi_n[, 1:32])
fdi_n <- fdi_n[,c(1,3,2, 4:32)]
#create full panel
library(gtools)
id1 <- data.frame(unique(names$Country)) # 186
years <- seq(2001, 2012)
panel <- expand.grid(x = id1[,1], y = id1[,1])
panel <- subset(panel, panel[,1] != panel[,2])
colnames(panel)[1] <- "Destination"
colnames(panel)[2] <- "Origin"
panel <- do.call("rbind", replicate(12, panel, simplify = FALSE)) # 408480
yearid <- data.frame()
for(i in years){
year <- data.frame(rep(i, length(names[,1])*(length(names[,1])-1)))
yearid <- rbind(yearid,year)
}
panel$Year <- yearid[,1]
rm(i, id1, years, yearid, year)
fdi_m <- merge(panel, fdi_n, by= c("Destination", "Origin", "Year"))
fdi_m <- na.omit(fdi_m)
View(fdi_m)
#write csv
write.csv(fdi_m, file = "sub_stock.csv")
#=============================================================#
# John Schoeneman
# Work Done For: FDI Network Analysis RA-IGERT
# Date: Fall 2016
# Work Done: Perform ERGM Count analysis
# Machine: MacPro OSX Yosemite
#=============================================================#
# clear workspace
rm(list=ls())
set.seed(19)
# libraries
library(ergm.count)
library(network)
library(igraph)
library(doBy)
library(plyr)
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#load in data
fdi <- read.csv("sub_stock.csv", stringsAsFactors=FALSE)        #FDI
fdi <- fdi[,-1]
length(subset(fdi$Value, fdi$Value==0))
length(subset(fdi$Value, fdi$Value==0))/189000
length(subset(fdi$Value, fdi$Value=<0))/189000
length(subset(fdi$Value, fdi$Value<00))/189000
length(subset(fdi$Value, fdi$Value<=0))/189000
length(subset(fdi$Value, fdi$Value<0))/189000
summary(subset(fdi$Value, fdi$Value!=0))/189000
summary(subset(fdi$Value, fdi$Value!=0))
summary(subset(fdi$Value, fdi$Value!=0))
#=============================================================#
# John Schoeneman
# Work Done For: FDI Network Analysis RA-IGERT
# Date: Fall 2016
# Work Done: Network Measures and MRQAP
# Machine: MacPro OSX Yosemite
#=============================================================#
# clear workspace
rm(list=ls())
set.seed(19)
# libraries
library(doBy)
library(foreach)
library(doMC)
library(stargazer)
library(RCurl)
library(plyr)
library(car)
library(MASS)
library(lattice)
#library(vioplot)
#no_cores <- detectCores()
#registerDoMC(no_cores)  #change the 2 to your number of CPU cores
setwd("/Users/johnpschoeneman/Documents/school/Penn State/MA Thesis/MA Code and Data")
#load in data
fdi <- read.csv("fdi_sub.csv", stringsAsFactors=FALSE)        #FDI
fdi <- fdi[,-1]
# create new variable transformations
fdi$Dest.GDP <- fdi$Dest.GDP/1000000
fdi$Origin.GDP <- fdi$Origin.GDP/1000000
fdi$trade_ln <- log(fdi$trade_int+1)
fdi$dyad <- paste(fdi$Destination, fdi$Origin, sep = "")
fdi$Value_of_gdp <- fdi$Value/fdi$Dest.GDP
fdi$Value_cu <- sign(fdi$Value) * abs(fdi$Value)^(1/3)
fdi$Value_ln <- log(1+fdi$Value/60000)
xvars<-c("contig","comlang_off", "comlang_ethno","colony", "comcol", "curcol",
"log(dist)","log(Dest.GDP*Origin.GDP)",
"defense.max.x","nonaggression.max.x", "neutrality.max.x","entente.max.x",
"Dest.polity","Origin.polity", "Dest.pv", "Origin.pv",
"Dest.TO", "Origin.TO", "Dest.GDP.g","Origin.GDP.g",
"depth_latent*log(trade_int+1)",
"Destination", "Origin", "as.factor(Year)")
MODEL<-as.formula(paste(paste("fdi$Value"," ~ ", paste(xvars,collapse="+"))))
fe4 <- lm(MODEL, data=fdi)
summary(fe4)
# Value cubed
MODEL<-as.formula(paste(paste("fdi$Value_cu"," ~ ", paste(xvars,collapse="+"))))
fe5 <- lm(MODEL, data=fdi)
summary(fe5)
fe_int <- lm(Value/Dest.GDP ~ log(trade_int+1)*depth_latent
, data=fdi)
summary(fe_int)
grid<-expand.grid(trade_int=seq(0,20,1),
depth_latent=seq(0,3.7,.1))
hats<-predict(fe_int, newdata=grid)
levelplot(hats~grid$trade_int*grid$depth_latent,
contour=TRUE,
cuts=12,pretty=TRUE,xlab="Supply Chain Trade",
ylab="PTA depth",
col.regions=heat.colors)
trellis.par.set("axis.line",list(col="transparent"))
theseCol=heat.colors(150)
wireframe(hats~grid$trade_int*grid$depth_latent,
drape=TRUE,
xlab=list("Supply Chain Trade",rot=30),
ylab=list("PTA Depth",rot=-40),
zlab=list("Predictions",rot=90),
col.regions=theseCol,
scales=list(arrows=FALSE,col="black"),
zoom=0.85,pretty=TRUE, arrows=FALSE)
sub <- subset(fdi, fdi$depth_latent>2 & log(fdi$trade_int+1)<5)
View(sub)
5205/189000
sub <- subset(fdi, fdi$depth_latent<2 & log(fdi$trade_int+1)>5)
sub <- subset(fdi, fdi$depth_latent>!2 & log(fdi$trade_int+1)<!5)
sub <- subset(fdi, fdi$depth_latent>2 | log(fdi$trade_int+1)<5)
sub <- subset(fdi, log(fdi$trade_int+1)>5)
sub <- fdi[!(fdi$depth_latent>2 & log(fdi$trade_int+1)<5,]
sub <- fdi[!(fdi$depth_latent>2 & log(fdi$trade_int+1)<5),]
fe_int <- lm(Value/Dest.GDP ~ log(trade_int+1)*depth_latent
, data=sub)
summary(fe_int)
grid<-expand.grid(trade_int=seq(0,20,1),
depth_latent=seq(0,3.7,.1))
hats<-predict(fe_int, newdata=grid)
levelplot(hats~grid$trade_int*grid$depth_latent,
contour=TRUE,
cuts=12,pretty=TRUE,xlab="Supply Chain Trade",
ylab="PTA depth",
col.regions=heat.colors)
trellis.par.set("axis.line",list(col="transparent"))
theseCol=heat.colors(150)
wireframe(hats~grid$trade_int*grid$depth_latent,
drape=TRUE,
xlab=list("Supply Chain Trade",rot=30),
ylab=list("PTA Depth",rot=-40),
zlab=list("Predictions",rot=90),
col.regions=theseCol,
scales=list(arrows=FALSE,col="black"),
zoom=0.85,pretty=TRUE, arrows=FALSE)
#=============================================================#
# John Schoeneman
# Work Done For: FDI Network Analysis RA-IGERT
# Date: Fall 2016
# Work Done: Perform ERGM Count analysis
# Machine: MacPro OSX Yosemite
#=============================================================#
# clear workspace
rm(list=ls())
set.seed(19)
# libraries
library(ergm.count)
library(network)
library(igraph)
library(doBy)
library(plyr)
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#load in data
fdi <- read.csv("sub_stock.csv", stringsAsFactors=FALSE)        #FDI
fdi <- fdi[,-1]
#201 countries, 12 years (2000-2012),
# create new variable transformations
fdi$Dest.GDP <- fdi$Dest.GDP/1000000 # scale to millions
fdi$Origin.GDP <- fdi$Origin.GDP/1000000
fdi$trade_ln <- log(fdi$trade_int+1)
fdi$dyad <- paste(fdi$Destination, fdi$Origin, sep = "")
fdi$Value_of_gdp <- fdi$Value/fdi$Dest.GDP
fdi$Value_ln <- round(log(ifelse(fdi$Value<0, 0, fdi$Value)+1))
#extract one year
fdi01 <- subset(fdi, fdi$Year ==2001)
fdi01$mass <- (log(fdi01$Dest.GDP*fdi01$Origin.GDP))
fdi01$dist <- log(fdi01$dist)
#edge attr: "contig","comlang_off", "comlang_ethno","colony","comcol", "curcol","dist",
#　　　　　 "defense.max.x","nonaggression.max.x","neutrality.max.x","entente.max.x",
#　　　　　 "depth_index", "depth_latent","trade_hco", "trade_int", "trade_cap", "trade_mix"
#create vertex dataset
vertex_attr <- summaryBy(Origin.GDP+Origin.polity+Origin.TO+Origin.pop+Origin.GDP.g+
Origin.pv ~ Origin, data=fdi01)
#vertex attr: "Origin.GDP","Origin.polity","Origin.TO", "Origin.pop",  "Origin.GDP.g",　Origin.pv"
#rename vertex dataset
names(vertex_attr) <- c("name","GDP", "Polity", "TradeOpen", "Pop", "GDP.g", "PV")
#=============================================================#
# John Schoeneman
# Work Done For: FDI Network Analysis RA-IGERT
# Date: Fall 2016
# Work Done: Perform ERGM Count analysis
# Machine: MacPro OSX Yosemite
#=============================================================#
# clear workspace
rm(list=ls())
set.seed(19)
# libraries
library(ergm.count)
library(network)
library(igraph)
library(doBy)
library(plyr)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#load in data
fdi <- read.csv("sub_stock.csv", stringsAsFactors=FALSE)        #FDI
fdi <- fdi[,-1]
# create new variable transformations
fdi$Dest.GDP <- fdi$Dest.GDP/1000000 # scale to millions
fdi$Origin.GDP <- fdi$Origin.GDP/1000000
fdi$trade_ln <- log(fdi$trade_int+1)
fdi$dyad <- paste(fdi$Destination, fdi$Origin, sep = "")
fdi$Value_of_gdp <- fdi$Value/fdi$Dest.GDP
fdi$Value_ln <- round(log(ifelse(fdi$Value<0, 0, fdi$Value)+1))
#extract one year
fdi01 <- subset(fdi, fdi$Year ==2001)
fdi01$mass <- (log(fdi01$Dest.GDP*fdi01$Origin.GDP))
fdi01$dist <- log(fdi01$dist)
#edge attr: "contig","comlang_off", "comlang_ethno","colony","comcol", "curcol","dist",
#　　　　　 "defense.max.x","nonaggression.max.x","neutrality.max.x","entente.max.x",
#　　　　　 "depth_index", "depth_latent","trade_hco", "trade_int", "trade_cap", "trade_mix"
#create vertex dataset
vertex_attr <- summaryBy(Origin.GDP+Origin.polity+Origin.TO+Origin.pop+Origin.GDP.g+
Origin.pv ~ Origin, data=fdi01)
#vertex attr: "Origin.GDP","Origin.polity","Origin.TO", "Origin.pop",  "Origin.GDP.g",　Origin.pv"
#rename vertex dataset
names(vertex_attr) <- c("name","GDP", "Polity", "TradeOpen", "Pop", "GDP.g", "PV")
#create network object
detach("package:igraph", unload=TRUE)
fdi_net <- network(fdi01, matrix.type="edgelist", directed=TRUE)
#set edge attributes
set.edge.attribute(fdi_net, attrname="Value_ln", value=fdi01$Value_ln)
set.edge.attribute(fdi_net, attrname="distance", value=fdi01$dist)
set.edge.attribute(fdi_net, attrname="contig", value=fdi01$contig)
set.edge.attribute(fdi_net, attrname="colony", value=fdi01$colony)
set.edge.attribute(fdi_net, attrname="lang_ethno", value=fdi01$comlang_ethno)
set.edge.attribute(fdi_net, attrname="defence_t", value=fdi01$defense.max.x)
set.edge.attribute(fdi_net, attrname="nonagg_t", value=fdi01$nonaggression.max.x)
set.edge.attribute(fdi_net, attrname="neut_t", value=fdi01$neutrality.max.x)
set.edge.attribute(fdi_net, attrname="entente_t", value=fdi01$entente.max.x)
set.edge.attribute(fdi_net, attrname="depth", value=fdi01$depth_latent)
set.edge.attribute(fdi_net, attrname="trade_int", value=fdi01$trade_int)
set.edge.attribute(fdi_net, attrname="mass", value=fdi01$mass)
#set.edge.attribute(fdi_net, attrname="shared_alliance", value=fdi01$share_partner)
#set vertex attributes
set.vertex.attribute(fdi_net, attrname="GDP", value=vertex_attr$GDP)
set.vertex.attribute(fdi_net, attrname="Polity", value=vertex_attr$GDP)
set.vertex.attribute(fdi_net, attrname="TradeOpen", value=vertex_attr$GDP)
#set.vertex.attribute(fdi_net, attrname="Pop", value=vertex_attr$GDP)
set.vertex.attribute(fdi_net, attrname="GDP.g", value=vertex_attr$GDP)
set.vertex.attribute(fdi_net, attrname="PV", value=vertex_attr$GDP)
#check network
fdi_net
list.edge.attributes(fdi_net)
row.names(vertex_attr) <- vertex_attr[,1]
#base formula for only network measures
formula <- fdi_net ~ sum + sum(pow=1/2)+ nonzero + mutual(form="geometric")
# count model
fit.01.1 <- ergm(formula,
#estimate='MLE',
response="Value_ln",
reference=~Poisson,
#verbose=TRUE,
control=control.ergm(MCMLE.trustregion=100,
MCMLE.maxit=50,
MCMC.samplesize=10000,
MCMC.burnin=500,
MCMC.interval=1000
#,MCMC.prop.weights="0inflated"
#,MCMC.prop.args=list(p0=0.75)
))
summary(fit.01.1)
formula <- fdi_net ~ sum + sum(pow=1/2)+ mutual(form="geometric") + nonzero +
transitiveties   + edgecov(fdi_net, "mass", form="sum")+
edgecov(fdi_net, "distance", form="sum")
fit.01.3 <- ergm(formula,
#estimate='MLE',
response="Value_ln",
reference=~Poisson,
#verbose=TRUE,
control=control.ergm(MCMLE.trustregion=100,
MCMLE.maxit=50,
MCMC.samplesize=10000,
MCMC.burnin=500,
MCMC.interval=1000
#,MCMC.prop.weights="0inflated"
#,MCMC.prop.args=list(p0=0.75)
))
summary(fit.01.3)
library(texreg)
texreg(l = list(fit.01.1, fit.01.3))
